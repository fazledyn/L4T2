{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy pandas pickle\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- Conv\\n- ReLU\\n- MaxPool\\n- Conv\\n- MaxPool\\n- Flatten\\n- Dense\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "\"\"\"\n",
    "- Conv\n",
    "- ReLU\n",
    "- MaxPool\n",
    "- Conv\n",
    "- MaxPool\n",
    "- Flatten\n",
    "- Dense\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"ConvolutionLayer\"\n",
    "\n",
    "    def __init__(self, n_filter, filter_size, stride, padding):\n",
    "        self.filter_size = filter_size\n",
    "        self.n_filter = n_filter\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.filters = None\n",
    "        self.biases = None\n",
    "\n",
    "    \n",
    "    def forward(self, input):        \n",
    "        batch_size, n_channel, height, width = input.shape\n",
    "        output_shape = (batch_size, self.n_filter, int((height - self.filter_size + 2*self.padding)/self.stride + 1), int((width - self.filter_size + 2*self.padding)/self.stride + 1))\n",
    "        output = np.zeros(output_shape)\n",
    "\n",
    "        if self.filters is None:\n",
    "            self.filters = np.random.randn(self.n_filter, n_channel, self.filter_size, self.filter_size) / np.sqrt(2 / (self.filter_size * self.filter_size * n_channel))\n",
    "        if self.biases is None:\n",
    "            self.biases = np.random.randn(self.n_filter)\n",
    "\n",
    "        if self.padding > 0:\n",
    "            input = np.pad(input, ((0,0), (0,0), (self.padding, self.padding), (self.padding, self.padding)), 'constant')\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            for c in range(self.n_filter):\n",
    "                for h in range(height):\n",
    "                    for w in range(width):\n",
    "                        output[b, c, h, w] = np.sum(input[b, :, h*self.stride :h*self.stride + self.filter_size, w*self.stride : w*self.stride + self.filter_size] * self.filters[c, :, :, :]) + self.biases[c]\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        # perform back propagation for convolution\n",
    "\n",
    "        batch_size, n_channel, height, width = output.shape\n",
    "        input_shape = (batch_size, n_channel, height, width)\n",
    "        input = np.zeros(input_shape)\n",
    "\n",
    "        if self.padding > 0:\n",
    "            output = np.pad(output, ((0,0), (0,0), (self.padding, self.padding), (self.padding, self.padding)), 'constant')\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            for c in range(self.n_filter):\n",
    "                for h in range(height):\n",
    "                    for w in range(width):\n",
    "                        input[b, :, h*self.stride :h*self.stride + self.filter_size, w*self.stride : w*self.stride + self.filter_size] += output[b, c, h, w] * self.filters[c, :, :, :,]\n",
    "                        #   did some numbo jumbo here (not sure if it's correct)\n",
    "                        #   under this comment line\n",
    "                        self.filters[c, :, :, :] -= learning_rate * output[b, c, h, w] * input[:, b, h*self.stride :h*self.stride + self.filter_size, w*self.stride : w*self.stride + self.filter_size]\n",
    "                        self.biases[c] -= learning_rate * output[b, c, h, w]\n",
    "        \n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLUActivationLayer:\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"ReLUActivationLayer\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        return np.maximum(input, 0)\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        return np.where(output > 0, 1, 0)\n",
    "\n",
    "\n",
    "class MaxPoolingLayer:\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"MaxPoolingLayer\"\n",
    "\n",
    "    def __init__(self, pool_size, stride):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size, n_channel, height, width = input.shape\n",
    "\n",
    "        output_h = int((height - self.pool_size)/self.stride + 1)\n",
    "        output_w = int((width  - self.pool_size)/self.stride + 1)\n",
    "\n",
    "        output_shape = (batch_size, n_channel, output_h, output_w)\n",
    "        output = np.zeros(output_shape)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for c in range(n_channel):\n",
    "                for h in range(output_h):\n",
    "                    for w in range(output_w):\n",
    "                        output[b, c, h, w] = np.max(input[b, :, h*self.stride :h*self.stride + self.pool_size, w*self.stride : w*self.stride + self.pool_size])\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        batch_size, n_channel, height, width = output.shape\n",
    "        input_shape = (batch_size, n_channel, height, width)\n",
    "        input = np.zeros(input_shape)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for c in range(n_channel):\n",
    "                for h in range(height):\n",
    "                    for w in range(width):\n",
    "                        input[b, c, h*self.stride :h*self.stride + self.pool_size, w*self.stride : w*self.stride + self.pool_size] = np.where(input[b, c, h*self.stride :h*self.stride + self.pool_size, w*self.stride : w*self.stride + self.pool_size] == np.max(input[b, c, h*self.stride :h*self.stride + self.pool_size, w*self.stride : w*self.stride + self.pool_size]), output[b, c, h, w], 0)\n",
    "\n",
    "        return input    \n",
    "        \n",
    "\n",
    "class SoftMaxLayer:\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"SoftMaxLayer\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        val = input - np.max(input, axis=1, keepdims=True)\n",
    "        val = np.exp(val) / np.exp(val).sum(axis=1, keepdims=True)\n",
    "        return val\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        return output\n",
    "\n",
    "\n",
    "class FlatteningLayer:\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"FlatteningLayer\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.reshape(input.shape[0], -1)\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        return output.reshape(output.shape[0], -1)\n",
    "\n",
    "\n",
    "class DenseLayer:\n",
    "\n",
    "    def __init__(self, n_output):\n",
    "        self.n_output = n_output\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"DenseLayer\"\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        batch_size, n_input = input.shape\n",
    "\n",
    "        if self.weights is None:\n",
    "            self.weights = np.random.randn(n_input, self.n_output) / np.sqrt(n_input)\n",
    "        if self.biases is None:\n",
    "            self.biases = np.random.randn(self.n_output)\n",
    "\n",
    "        output = np.dot(input, self.weights) + self.biases\n",
    "        return output\n",
    "\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "            \n",
    "            batch_size, n_input = output.shape\n",
    "    \n",
    "            input = np.dot(output, self.weights.T)\n",
    "            self.weights -= learning_rate * np.dot(output.T, input)\n",
    "            self.biases -= learning_rate * output.sum(axis=0)\n",
    "    \n",
    "            return input\n",
    "        \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetModel:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.layers)\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def set_loss(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "    \n",
    "    def predict(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "    \n",
    "    def fit(self, x, y, learning_rate=0.01, epochs=1000):\n",
    "        for i in range(epochs):\n",
    "            out = self.predict(x)\n",
    "            error = self.loss(y, out)\n",
    "            if i % 100 == 0:\n",
    "                print(\"Epoch %d, loss: %f\" % (i, error))\n",
    "            \n",
    "            gradient = self.loss_prime(y, out)\n",
    "            for layer in reversed(self.layers):\n",
    "                gradient = layer.backward(gradient, learning_rate)\n",
    "        \n",
    "        print(\"Final loss: %f\" % self.loss(y, self.predict(x)))\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        out = self.predict(x)\n",
    "        return self.loss(y, out)\n",
    "    \n",
    "    def accuracy(self, x, y):\n",
    "        out = self.predict(x)\n",
    "        return np.mean(np.argmax(out, axis=1) == np.argmax(y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "def loss_prime(y_true, y_pred):\n",
    "    return 2*(y_pred - y_true)\n",
    "\n",
    "BASEDIR = \"../../../numta\"\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"Load the dataset from the base directory\"\"\"\n",
    "    \n",
    "    dataset = f\"{BASEDIR}/training-a.csv\"\n",
    "    df = pd.read_csv(dataset)\n",
    "    df = df[[\"filename\", \"digit\"]]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def load_image(image_name):\n",
    "    \n",
    "    img = cv2.imread(f\"{BASEDIR}/training-a/{image_name}\")\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.invert(img)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    print(img)\n",
    "    return img\n",
    "\n",
    "# data = load_dataset()\n",
    "# data.head\n",
    "\n",
    "# X = data[\"filename\"].values\n",
    "# y = data[\"digit\"].values\n",
    "\n",
    "# load_image(X[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 32, 32)\n",
      "(10, 10)\n",
      "[[5.99346376e-101 1.87739404e-124 9.90158452e-126 6.45105633e-112\n",
      "  3.33333495e-011 1.12873676e-094 1.00000000e+000 4.08609673e-142\n",
      "  4.05429668e-162 3.11545028e-037]\n",
      " [2.91443645e-096 4.21072153e-116 3.71093131e-118 4.82522920e-104\n",
      "  9.86186626e-029 2.39800808e-082 4.76877275e-014 5.28253186e-096\n",
      "  1.02425062e-129 1.00000000e+000]\n",
      " [5.96534074e-144 9.11312842e-166 4.87613127e-140 3.78100983e-131\n",
      "  1.56766365e-021 4.89874148e-110 2.00556738e-031 8.46137031e-166\n",
      "  3.01975523e-186 1.00000000e+000]\n",
      " [2.81634797e-116 8.36683806e-149 1.14117856e-149 3.10094048e-141\n",
      "  3.79522708e-047 6.19782525e-107 1.00000000e+000 3.80151231e-157\n",
      "  2.89700528e-203 2.93039976e-023]\n",
      " [5.34519646e-121 6.98746112e-110 2.78225887e-142 4.07312993e-097\n",
      "  7.19876779e-032 5.96263073e-089 9.77600369e-016 2.17785554e-102\n",
      "  1.15018511e-193 1.00000000e+000]\n",
      " [1.76987890e-124 3.23074242e-151 3.92116321e-135 1.09694713e-103\n",
      "  3.34256692e-050 4.59648018e-104 1.21135605e-032 2.56265066e-137\n",
      "  1.51442612e-170 1.00000000e+000]\n",
      " [9.03396413e-139 1.14193464e-117 2.86283550e-120 1.74301447e-116\n",
      "  7.77056136e-031 5.29865922e-093 2.36128552e-031 9.63259839e-121\n",
      "  3.17645457e-191 1.00000000e+000]\n",
      " [1.67854104e-111 1.62268140e-137 2.50842740e-113 1.09297919e-102\n",
      "  1.37327510e-046 7.05674922e-076 9.99967922e-001 3.76822773e-103\n",
      "  1.35324246e-172 3.20782307e-005]\n",
      " [1.77796616e-122 3.95534324e-134 1.47750654e-105 9.42421988e-097\n",
      "  1.07660280e-024 3.11740004e-106 1.13520904e-027 1.13679681e-118\n",
      "  9.52586084e-188 1.00000000e+000]\n",
      " [3.77223841e-152 4.52187676e-127 2.62153077e-116 2.47376282e-136\n",
      "  5.47203170e-053 5.85298749e-092 1.38323710e-013 4.65166772e-121\n",
      "  3.14702196e-202 1.00000000e+000]]\n",
      "Sum of final 10.0\n"
     ]
    }
   ],
   "source": [
    "# batch_size, n_channel, height, width\n",
    "# input_shape = (10, 10, 30, 30)\n",
    "# input = np.random.randint(-2, 2, size=input_shape)\n",
    "input = np.random.randn(10, 10, 32, 32)\n",
    "\n",
    "# n_filter, filter_size, stride, padding\n",
    "con = ConvolutionLayer(n_filter=5, filter_size=3, stride=1, padding=1)\n",
    "relu = ReLUActivationLayer()\n",
    "max = MaxPoolingLayer(pool_size=2, stride=1)\n",
    "flat = FlatteningLayer()\n",
    "dens = DenseLayer(n_output=10)\n",
    "smax = SoftMaxLayer()\n",
    "\n",
    "output = con.forward(input)\n",
    "output = relu.forward(output)\n",
    "output = max.forward(output)\n",
    "output = flat.forward(output)\n",
    "output = dens.forward(output)\n",
    "output = smax.forward(output)\n",
    "\n",
    "print(input.shape)\n",
    "print(output.shape)\n",
    "\n",
    "# print(input)\n",
    "print(output)\n",
    "print(\"Sum of final\", output.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
